What is Benford's Law?

Benford’s Law, also called the First-Digit Law, describes the frequency distribution of the leading digits (i.e., the first digit) in many real-world numerical datasets.
📊 Benford’s Law Expected Distribution

According to Benford’s Law, the first digit is more likely to be small. Here's the expected probability of each digit (1 to 9) appearing as the first digit:
First Digit	Probability (%)
1	30.1%
2	17.6%
3	12.5%
4	9.7%
5	7.9%
6	6.7%
7	5.8%
8	5.1%
9	4.6%

This means about 1 in 3 numbers in naturally occurring data will start with the digit 1.
🧠 Why Does This Happen?

Benford’s Law emerges from multiplicative growth, scaling laws, and datasets that span multiple orders of magnitude. Common examples include:

    Populations

    Financial data (sales, expenses, tax returns)

    Natural constants

    Stock prices

    Scientific measurements

The key condition: data must not be artificially bounded or uniformly distributed.
🕵️ Applications of Benford’s Law

Benford's Law is widely used to:

    Detect anomalies or fraud (e.g., in accounting, tax records, elections)

    Audit financial statements

    Validate synthetic or manipulated datasets

If a dataset deviates significantly from Benford’s Law, it might suggest:

    Human manipulation

    Data fabrication

    Systematic bias

🧮 How It Works in Practice

To apply it:

    Take all values in a numeric column.

    Extract the first non-zero digit from each value.

    Count the frequencies of digits 1–9.

    Compare against the Benford expected distribution.

    Use tests like:

        MAD (Mean Absolute Deviation) – how far actual values deviate on average.

        Chi-Square Test – statistical test of goodness-of-fit.

🛑 When It Doesn’t Apply

Benford's Law may not apply to:

    Datasets with a small range (e.g., all salaries between 40,000 and 60,000)

    Arbitrarily truncated or rounded data

    Assigned numbers (e.g., phone numbers, ID numbers)
