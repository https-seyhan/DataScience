import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, losses, InputExample
from torch.utils.data import DataLoader
import torch
from sklearn.preprocessing import OrdinalEncoder
from sklearn.model_selection import train_test_split

# ðŸ“Œ Load Sample Dataset
data = {
    'OrderedCategory': ['Low', np.nan, 'High', 'Medium', np.nan, 'Low', 'Medium', 'High', np.nan, 'Medium'],
    'TextFeature': [
        "Minor safety issue reported",
        "Risk of falling objects is high",
        "Severe flooding at the site",
        "Some safety concerns raised",
        "Potential hazard identified",
        "Low-impact site risk identified",
        "Workers reported some risk",
        "Major accident risk detected",
        "Hazardous area spotted",
        "Worksite safety moderate"
    ]
}
df = pd.DataFrame(data)

# ðŸ“Œ Encode Ordered Category (Ordinal Encoding)
ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])
df['OrderedCategory_encoded'] = ordinal_encoder.fit_transform(df[['OrderedCategory']])

# ðŸ“Œ Separate Data with & without Missing Values
df_known = df.dropna(subset=['OrderedCategory'])
df_missing = df[df['OrderedCategory'].isna()]

X_texts = df_known['TextFeature'].values
y_labels = df_known['OrderedCategory_encoded'].ravel()

# ðŸ“Œ Split into Train and Test Sets
X_train, X_test, y_train, y_test = train_test_split(X_texts, y_labels, test_size=0.2, random_state=42)

# ðŸ“Œ Convert to Sentence Transformer Training Format
train_examples = [InputExample(texts=[text], label=float(label)) for text, label in zip(X_train, y_train)]
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)

# ðŸ“Œ Load Pretrained sBERT Model
model = SentenceTransformer('all-MiniLM-L6-v2')

# ðŸ“Œ Define Loss Function (Regression Loss for Ordered Categories)
train_loss = losses.CosineSimilarityLoss(model)

# ðŸ“Œ Train the Model
model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=5, warmup_steps=100)

# ðŸ“Œ Use Fine-Tuned Model to Predict Missing Categories
df_missing['TextEmbedding'] = df_missing['TextFeature'].apply(lambda x: model.encode(x))
X_missing = np.vstack(df_missing['TextEmbedding'].values)

# ðŸ“Œ Map to Nearest Label
predicted_labels = np.round(model.predict(X_missing)).astype(int)
df_missing['ImputedCategory'] = ordinal_encoder.inverse_transform(predicted_labels.reshape(-1, 1))

# ðŸ“Œ Merge Imputed Values Back
df.loc[df['OrderedCategory'].isna(), 'OrderedCategory'] = df_missing['ImputedCategory']
print(df[['TextFeature', 'OrderedCategory']])
#âœ… Fine-Tuning Adapts sBERT to Your Risk Data â€“ It understands domain-specific safety terminology.
#âœ… Cosine Similarity Loss Captures Ordered Categories â€“ Helps predict Low â†’ Medium â†’ High accurately.
#âœ… No Need for Extra Models â€“ After training, you can use sBERT directly to predict missing risk levels.
